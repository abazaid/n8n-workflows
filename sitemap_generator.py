from fastapi import APIRouter, Response
from xml.etree.ElementTree import Element, SubElement, tostring
from datetime import datetime
from workflow_db import WorkflowDatabase
from pathlib import Path
import json

router = APIRouter()
db = WorkflowDatabase()

@router.get("/sitemap.xml", response_class=Response)
async def sitemap():
    """ØªÙˆÙ„ÙŠØ¯ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ù…ÙˆÙ‚Ø¹ (sitemap.xml) Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠÙ‹Ø§ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙØ­Ø§Øª ÙˆØ§Ù„Ù€ workflows"""
    urlset = Element("urlset", xmlns="http://www.sitemaps.org/schemas/sitemap/0.9")

    base_url = "https://workflowsbase.com"

    def add_url(loc, changefreq="weekly", priority="0.8"):
        url = SubElement(urlset, "url")
        SubElement(url, "loc").text = loc
        SubElement(url, "changefreq").text = changefreq
        SubElement(url, "priority").text = priority

    # âœ… 1. Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    add_url(f"{base_url}/", changefreq="weekly", priority="1.0")

    # âœ… 2. ØµÙØ­Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ø§Ù…Ø©
    add_url(f"{base_url}/api/workflows", changefreq="weekly", priority="0.8")

# âœ… 3. Ø±ÙˆØ§Ø¨Ø· Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ Workflows Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
try:
    workflows, total = db.search_workflows(limit=5000, offset=0)
    for wf in workflows:
        filename = wf.get("filename")
        name = wf.get("name", "").replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
        updated_at = wf.get("updated_at") or wf.get("created_at")

        if filename:
            url = SubElement(urlset, "url")

            # ğŸ”¹ Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙØ­Ø©
            SubElement(url, "loc").text = f"{base_url}/api/workflows/{filename}"

            # ğŸ”¹ Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ« Ø¨ØµÙŠØºØ© Google Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠØ© (YYYY-MM-DD)
            if updated_at:
                try:
                    # Ù„Ùˆ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù…Ø­ÙÙˆØ¸ ÙƒÙ†Øµ Ù†Ø­Ø§ÙˆÙ„ Ù†Ø­ÙˆÙ„Ù‡
                    date_str = str(updated_at).split(" ")[0]
                except:
                    date_str = datetime.utcnow().strftime("%Y-%m-%d")
            else:
                date_str = datetime.utcnow().strftime("%Y-%m-%d")

            SubElement(url, "lastmod").text = date_str

            # ğŸ”¹ ØªÙƒØ±Ø§Ø± Ø§Ù„ØªØ­Ø¯ÙŠØ«
            SubElement(url, "changefreq").text = "monthly"

            # ğŸ”¹ Ø£ÙˆÙ„ÙˆÙŠØ© Ù…ØªÙˆØ³Ø·Ø©
            SubElement(url, "priority").text = "0.6"

            # ğŸ”¹ Ø£Ø¶Ù Ø§Ù„Ø§Ø³Ù… ÙƒØªÙ€Ø¹Ù„ÙŠÙ‚ (Ù„ÙŠØ³ Ø¹Ù†ØµØ±) Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù‚Ø§Ø¨Ù„ÙŠØ© Ù„Ù„Ù‚Ø±Ø§Ø¡Ø©
            if name:
                url.append(Comment(f" Workflow Name: {name} "))

except Exception as e:
    print(f"âš ï¸ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„Ù€ workflows: {e}")

    # âœ… 4. Ø±ÙˆØ§Ø¨Ø· Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª (Categories) ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§
    categories_file = Path("context/unique_categories.json")
    if categories_file.exists():
        try:
            with open(categories_file, "r", encoding="utf-8") as f:
                categories = json.load(f)
            for cat in categories:
                slug = cat.replace(" ", "-").lower()
                add_url(f"{base_url}/api/workflows/category/{slug}", changefreq="monthly", priority="0.5")
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª: {e}")
    else:
        # fallback
        default_categories = ["ai-ml", "marketing", "ecommerce", "messaging"]
        for cat in default_categories:
            add_url(f"{base_url}/api/workflows/category/{cat}", changefreq="monthly", priority="0.5")

    # âœ… 5. ØªÙˆÙ„ÙŠØ¯ XML Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    xml_str = tostring(urlset, encoding="utf-8", method="xml")
    return Response(content=xml_str, media_type="application/xml")
